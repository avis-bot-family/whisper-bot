services:
  whisper-bot:
    build:
      context: ../
      dockerfile: docker/bot.Dockerfile
    container_name: whisper-bot
    restart: unless-stopped
    env_file: ../.docker.env
    ports:
      - ${DOCKER_BOT_PORT:-8081}:8081
    # command: poetry run python3 ./bot/main.py
    command: sleep infinity
    volumes:
      - ../src/bot:/opt/bot
    networks:
      - whisper-network
    # Поддержка NVIDIA GPU
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

  ollama:
    image: ollama/ollama
    container_name: whisper-bot-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - whisper-network
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
    command: ["/bin/sh", "-c", "ollama pull ${OLLAMA_MODEL:-llama3.2} && exec ollama serve"]

networks:
  whisper-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16

volumes:
  ollama_data:
