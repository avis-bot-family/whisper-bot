services:
  whisper-bot:
    build:
      context: ../
      dockerfile: docker/bot.Dockerfile
    container_name: whisper-bot
    restart: unless-stopped
    env_file: ../.docker.env
    ports:
      - ${DOCKER_BOT_PORT:-8081}:8081
    command: poetry run python3 ./bot/main.py
    # command: sleep infinity
    volumes:
      - ../src/bot:/opt/bot
      - transcribe_data:/data/tasks
    networks:
      - whisper-network
    environment:
      - summary_BASE_URL=http://ollama:11434/v1
      - transcribe_WHISPER_SERVICE_URL=http://transcribe-worker:8000
      - transcribe_TASKS_DIR=/data/tasks
    depends_on:
      - transcribe-worker
      - ollama

  transcribe-worker:
    build:
      context: ../
      dockerfile: docker/worker.Dockerfile
    container_name: whisper-bot-worker
    restart: unless-stopped
    env_file: ../.docker.env
    volumes:
      - ../src/transcribe_worker:/opt/transcribe_worker
      - transcribe_data:/data/tasks
    networks:
      - whisper-network
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - worker_DEVICE=cuda

  ollama:
    image: ollama/ollama
    container_name: whisper-bot-ollama
    entrypoint: ["/bin/sh", "-c"]
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - whisper-network
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
    command: ["ollama serve & sleep 5 && ollama pull ${OLLAMA_MODEL:-llama3.2} && wait"]

networks:
  whisper-network:

volumes:
  transcribe_data:
  ollama_data:
